{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "-----------------------------------\n",
    "\n",
    "Here we're training on a pretty large dataset of infected and uninfected images. To download the dataset yourself, you can go [here](https://www.kaggle.com/iarunava/cell-images-for-detecting-malaria/download)\n",
    "\n",
    "## Setting up the dataset\n",
    "\n",
    "Follow the steps below to get your dataset set up.\n",
    " - Extract the downloaded zip\n",
    " - Rename `cell_images` to `train_cell_images`\n",
    " - Create a directory called `model`. This is where the trained model will be saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load infected images\n",
    "Parasitized = os.listdir(\"./dataset/train_cell_images/Parasitized/\")\n",
    "for p in Parasitized:\n",
    "    try:\n",
    "        image = cv2.imread(\"./dataset/train_cell_images/Parasitized/\" + p)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((50, 50))\n",
    "        rotated45 = size_image.rotate(45)\n",
    "        rotated75 = size_image.rotate(75)\n",
    "        blur = cv2.blur(np.array(size_image), (10, 10))\n",
    "        data.append(np.array(size_image))\n",
    "        data.append(np.array(rotated45))\n",
    "        data.append(np.array(rotated75))\n",
    "        data.append(np.array(blur))\n",
    "        labels.append(0.0)\n",
    "        labels.append(0.0)\n",
    "        labels.append(0.0)\n",
    "        labels.append(0.0)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "# Load uninfected images\n",
    "Uninfected = os.listdir(\"./dataset/train_cell_images/Uninfected/\")\n",
    "for u in Uninfected:\n",
    "    try:\n",
    "        image = cv2.imread(\"./dataset/train_cell_images/Uninfected/\" + u)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((50, 50))\n",
    "        rotated45 = size_image.rotate(45)\n",
    "        rotated75 = size_image.rotate(75)\n",
    "        data.append(np.array(size_image))\n",
    "        data.append(np.array(rotated45))\n",
    "        data.append(np.array(rotated75))\n",
    "        labels.append(1.0)\n",
    "        labels.append(1.0)\n",
    "        labels.append(1.0)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "# Convert image pixels to numpy arrays for easy processing\n",
    "cells = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "np.save(\"model/cells\", cells)\n",
    "np.save(\"model/labels\", labels)\n",
    "\n",
    "cells = np.load(\"model/cells.npy\")\n",
    "labels = np.load(\"model/labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72339, 50, 50, 3)\n",
      "(72339,)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle cells to prevent some sort of bias\n",
    "s = np.arange(cells.shape[0])\n",
    "np.random.shuffle(s)\n",
    "cells = cells[s]\n",
    "labels = labels[s]\n",
    "\n",
    "num_classes = len(np.unique(labels))\n",
    "len_data = len(cells)\n",
    "\n",
    "# Split into train and test datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(cells, labels)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255  # Normalize RGB values by dividing with 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "train_len = len(x_train)\n",
    "test_len = len(x_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 50, 50, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 25, 25, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 500)               1152500   \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 1,176,585\n",
      "Trainable params: 1,176,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 72339 samples, validate on 24114 samples\n",
      "Epoch 1/20\n",
      "72339/72339 [==============================] - 10s 135us/step - loss: 0.5453 - accuracy: 0.6965 - val_loss: 0.4367 - val_accuracy: 0.8059\n",
      "Epoch 2/20\n",
      "72339/72339 [==============================] - 8s 110us/step - loss: 0.3116 - accuracy: 0.8644 - val_loss: 0.1864 - val_accuracy: 0.9279\n",
      "Epoch 3/20\n",
      "72339/72339 [==============================] - 8s 110us/step - loss: 0.1543 - accuracy: 0.9435 - val_loss: 0.1304 - val_accuracy: 0.9531\n",
      "Epoch 4/20\n",
      "72339/72339 [==============================] - 8s 110us/step - loss: 0.1240 - accuracy: 0.9569 - val_loss: 0.1205 - val_accuracy: 0.9581\n",
      "Epoch 5/20\n",
      "72339/72339 [==============================] - 8s 109us/step - loss: 0.1154 - accuracy: 0.9594 - val_loss: 0.1157 - val_accuracy: 0.9601\n",
      "Epoch 00005: early stopping\n",
      "24114/24114 [==============================] - 3s 108us/step\n",
      "\n",
      " Validation accuracy:  0.9601476192474365\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        min_delta=1e-2,\n",
    "        patience=2,\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "# Create a sequential keras model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(50, 50, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "# compile the model with loss function as binary_crossentropy and using adam optimizer you can test result by trying\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit (train) the model. Using a batch size which is x^2 optimizes training on my GPU\n",
    "model.fit(x_train, y_train, batch_size=512, epochs=20, verbose=1, callbacks=callbacks, validation_data=(x_test, y_test))\n",
    "\n",
    "accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('\\n', 'Validation accuracy: ', accuracy[1])\n",
    "\n",
    "model.save('./model/cells.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "------------------\n",
    "\n",
    "## Setting up prediction dataset\n",
    " - Create a directory called `test_cell_images`\n",
    " - Copy any two images of your choosing into this directory. Name them `test1` and `test2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the type of cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted cell is an Infected cell.\n",
      "The predicted cell is an Uninfected cell.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def convert_to_array(img):\n",
    "    im = cv2.imread(img)\n",
    "    img_ = Image.fromarray(im, 'RGB')\n",
    "    image = img_.resize((50, 50))\n",
    "    image = np.array(image)\n",
    "    image = image / 255\n",
    "    return np.array([image])\n",
    "\n",
    "\n",
    "def get_cell_name(label):\n",
    "    if label == 0:\n",
    "        return \"Infected\"\n",
    "    if label == 1:\n",
    "        return \"Uninfected\"\n",
    "\n",
    "\n",
    "def predict_cell(file):\n",
    "    model = load_model('./model/cells.h5')\n",
    "    arr = convert_to_array(file)\n",
    "    score = model.predict(arr, verbose=3)\n",
    "    cell = get_cell_name(round(score[0][0]))\n",
    "    return \"The predicted cell is an \" + cell + \" cell.\"\n",
    "\n",
    "\n",
    "print(predict_cell('./dataset/test_cell_images/test1.png')) # Infected\n",
    "print(predict_cell('./dataset/test_cell_images/test2.png')) # Not infected\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
