{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing Necessary Libraries.\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np  # linear algebra\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Load infected images\n",
    "Parasitized = os.listdir(\"./dataset/train_cell_images/Parasitized/\")\n",
    "for p in Parasitized:\n",
    "    try:\n",
    "        image = cv2.imread(\"./dataset/train_cell_images/Parasitized/\" + p)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((50, 50))\n",
    "        rotated45 = size_image.rotate(45)\n",
    "        rotated75 = size_image.rotate(75)\n",
    "        blur = cv2.blur(np.array(size_image), (10, 10))\n",
    "        data.append(np.array(size_image))\n",
    "        data.append(np.array(rotated45))\n",
    "        data.append(np.array(rotated75))\n",
    "        data.append(np.array(blur))\n",
    "        labels.append(0.0)\n",
    "        labels.append(0.0)\n",
    "        labels.append(0.0)\n",
    "        labels.append(0.0)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "# Load uninfected images\n",
    "Uninfected = os.listdir(\"./dataset/train_cell_images/Uninfected/\")\n",
    "for u in Uninfected:\n",
    "    try:\n",
    "        image = cv2.imread(\"./dataset/train_cell_images/Uninfected/\" + u)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((50, 50))\n",
    "        rotated45 = size_image.rotate(45)\n",
    "        rotated75 = size_image.rotate(75)\n",
    "        data.append(np.array(size_image))\n",
    "        data.append(np.array(rotated45))\n",
    "        data.append(np.array(rotated75))\n",
    "        labels.append(1.0)\n",
    "        labels.append(1.0)\n",
    "        labels.append(1.0)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "# Convert image pixels to numpy arrays for easy processing\n",
    "cells = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "np.save(\"model/cells\", cells)\n",
    "np.save(\"model/labels\", labels)\n",
    "\n",
    "cells = np.load(\"model/cells.npy\")\n",
    "labels = np.load(\"model/labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72339, 50, 50, 3)\n",
      "(72339,)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle cells to prevent some sort of bias\n",
    "s = np.arange(cells.shape[0])\n",
    "np.random.shuffle(s)\n",
    "cells = cells[s]\n",
    "labels = labels[s]\n",
    "\n",
    "num_classes = len(np.unique(labels))\n",
    "len_data = len(cells)\n",
    "\n",
    "# Split into train and test datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(cells, labels)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255  # Normalize RGB values by dividing with 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "train_len = len(x_train)\n",
    "test_len = len(x_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 50, 50, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 25, 25, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1000)              2305000   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 2,829,585\n",
      "Trainable params: 2,829,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 72339 samples, validate on 24114 samples\n",
      "Epoch 1/20\n",
      "72339/72339 [==============================] - 11s 152us/step - loss: 0.5525 - accuracy: 0.6876 - val_loss: 0.4045 - val_accuracy: 0.8249\n",
      "Epoch 2/20\n",
      "72339/72339 [==============================] - 9s 121us/step - loss: 0.2563 - accuracy: 0.8916 - val_loss: 0.1492 - val_accuracy: 0.9487\n",
      "Epoch 3/20\n",
      "72339/72339 [==============================] - 9s 124us/step - loss: 0.1389 - accuracy: 0.9513 - val_loss: 0.1293 - val_accuracy: 0.9550\n",
      "Epoch 4/20\n",
      "72339/72339 [==============================] - 8s 115us/step - loss: 0.1198 - accuracy: 0.9582 - val_loss: 0.1142 - val_accuracy: 0.9588\n",
      "Epoch 5/20\n",
      "72339/72339 [==============================] - 8s 114us/step - loss: 0.1039 - accuracy: 0.9640 - val_loss: 0.1112 - val_accuracy: 0.9608\n",
      "Epoch 6/20\n",
      "72339/72339 [==============================] - 8s 114us/step - loss: 0.0955 - accuracy: 0.9665 - val_loss: 0.1066 - val_accuracy: 0.9623\n",
      "Epoch 00006: early stopping\n",
      "24114/24114 [==============================] - 2s 97us/step\n",
      "\n",
      " Validation accuracy:  0.9622625708580017\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        min_delta=1e-2,\n",
    "        patience=2,\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "# Create a sequential keras model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(50, 50, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(500, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))  # 2 represent output layer neurons\n",
    "model.summary()\n",
    "\n",
    "# compile the model with loss function as binary_crossentropy and using adam optimizer you can test result by trying\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit (train) the model. Using a batch size which is x^2 optimizes training on my GPU\n",
    "model.fit(x_train, y_train, batch_size=512, epochs=20, verbose=1, callbacks=callbacks, validation_data=(x_test, y_test))\n",
    "\n",
    "accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('\\n', 'Validation accuracy: ', accuracy[1])\n",
    "\n",
    "model.save('./model/cells.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
